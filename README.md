# üöÄ Projeto_MVP_Engenharia_de_Dados

üìå Descri√ß√£o

Este projeto tem como foco analisar os chamados registrados na plataforma 311 da cidade de Nova York no ano de 2024, utilizando Databricks, PySpark e SQL para processar e transformar os dados. O intuito √© construir um pipeline de dados estruturado nas camadas Bronze, Silver e Gold, permitindo avaliar a efici√™ncia dos atendimentos por ag√™ncia.

üìÅ Estrutura do Projeto

1Ô∏è‚É£ Ingest√£o de Dados: Importa√ß√£o dos arquivos CSV contendo os atendimentos e suas respectivas informa√ß√µes.

2Ô∏è‚É£ Transforma√ß√£o e Limpeza: Padroniza√ß√£o de colunas, tratamento de valores nulos e formata√ß√£o das datas.

3Ô∏è‚É£ Modelagem de Dados (Esquema Estrela):

  * Tabela Fato (Fato_Unique_Key): Cont√©m os dados principais dos atendimentos.

  * Tabelas Dimens√£o:
    * Dim_Agencia: Informa√ß√µes sobre as ag√™ncias que mais tiveram atendimentos
    
    * Dim_Tempo: Detalhes temporais dos atendimentos.
      

üåü Esquema Estrela

As tabelas est√£o estruturadas da seguinte forma:

#### üóÇÔ∏è Tabela Fato: `Fato_Atendimentos`

| üè∑Ô∏è Coluna                 | üìå Tipo  | üîë Chave            | üìñ Descri√ß√£o                              |
|---------------------------|---------|---------------------|------------------------------------------|
| ID_Unique_Key            | STRING  | PK               | Identificador √∫nico do atendimento      |
| ID_Agencia               | STRING  | üîó FK ‚Üí Dim_Agencia | Identificador da ag√™ncia respons√°vel    |
| ID_Data                  | STRING  | üîó FK ‚Üí Dim_Tempo   | Identificador da data do atendimento    |
| Execution_Time_Seconds   | INT     | -                   | Tempo total do atendimento (em segundos) |
| Status                   | STRING  | -                   | Status do chamado                       |

#### üóÇÔ∏è Tabela Dimens√£o: `Dim_Agencia`

| üè∑Ô∏è Coluna   | üìå Tipo  | üîë Chave  | üìñ Descri√ß√£o                  |
|------------|---------|----------|--------------------------------|
| ID_Agencia | STRING  | PK    | Identificador √∫nico da ag√™ncia |
| Agency     | STRING  | -        | Sigla da ag√™ncia              |
| Agency_Name| STRING  | -        | Nome completo da ag√™ncia      |

#### üóÇÔ∏è Tabela Dimens√£o: `Dim_Tempo`

| üè∑Ô∏è Coluna        | üìå Tipo  | üîë Chave  | üìñ Descri√ß√£o                           |
|------------------|---------|----------|---------------------------------------|
| ID_Data        | STRING  | PK       | Identificador √∫nico da data (YYYYMMDD) |
| Ano            | INT     | -        | Ano do atendimento                    |
| M√™s            | INT     | -        | M√™s do atendimento                    |
| Dia            | INT     | -        | Dia do atendimento                    |
| Dia_da_Semana  | STRING  | -        | Nome do dia da semana                 |


üõ†Ô∏è Tecnologias Utilizadas:

üíæ Databricks para processamento e armazenamento.

üî• PySpark para processamento distribu√≠do.

üõ¢Ô∏è SQL para consultas

üîÆ Poss√≠veis Melhorias Futuras
‚ú® Implementa√ß√£o de pipeline automatizado para atualiza√ß√£o dos dados.
üìä Cria√ß√£o de dashboards para visualiza√ß√£o dos KPIs de atendimento.

---

Observa√ß√µes:

Este reposit√≥rio cont√©m dois notebooks:


- *Notebook Databricks* (.dbc): otimizado para ser importado diretamente no Databricks, com todas as c√©lulas j√° executadas.
- *Notebook em Python* (.ipynb): pode ser executado em Jupyter, Google Colab ou reimportado no Databricks.


## 1. Importar o Notebook Databricks

Para visualizar e executar o notebook diretamente no Databricks:

1Ô∏è‚É£ Baixe o arquivo [Projeto_MVP_Engenharia_de_Dados.dbc](Projeto_MVP_Engenharia_de_Dados.dbc)

2Ô∏è‚É£ Acesse seu workspace Databricks.

3Ô∏è‚É£ No menu √† esquerda, v√° at√© a aba *Workspace*.

4Ô∏è‚É£ Clique com o bot√£o direito sobre a pasta onde deseja importar > *Import*.

5Ô∏è‚É£ Selecione o arquivo .dbc e clique em *Import*.

6Ô∏è‚É£ O notebook ser√° exibido com *todos os outputs salvos* e estar√° pronto para *reexecu√ß√£o* se necess√°rio.

---

## 2. Executar o Notebook em Python (Google Colab)

1Ô∏è‚É£ Importar os dados no Databricks;

2Ô∏è‚É£ Executar todos os c√≥digos;

3Ô∏è‚É£ Validar os Resultados.

4Ô∏è‚É£ Clique no bot√£o abaixo para abrir diretamente no Google Colab:

[![Abrir no Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/HuriAnn/mvp-chamados-analytics/blob/main/Projeto_MVP_Engenharia_de_Dados.ipynb)

